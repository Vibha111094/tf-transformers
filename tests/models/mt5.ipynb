{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d7e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is intented to test, some of the\n",
    "# results validation of T5 model \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/sidhu/Projects/tf-transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5eac58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_transformers.models import MT5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49166bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:absl:Successful: Converted model using TF HF\n",
      "INFO:absl:Successful: Saved model at /tmp/tf_transformers_cache/google/mt5-small/ckpt-1\n",
      "INFO:absl:Successful: Asserted and Converted `google/mt5-small` from HF and saved it in cache folder /tmp/tf_transformers_cache/google/mt5-small\n"
     ]
    }
   ],
   "source": [
    "# Check TF conversion\n",
    "\n",
    "!rm -rf /tmp/tf_transformers_cache/google/mt5-small\n",
    "\n",
    "model_name = 'google/mt5-small'\n",
    "model, config = MT5Model.get_model(model_name=model_name, convert_fn_type='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc82879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:absl:Successful: Converted model using PT HF\n",
      "INFO:absl:Successful: Saved model at /tmp/tf_transformers_cache/google/mt5-small/ckpt-1\n",
      "INFO:absl:Successful: Asserted and Converted `google/mt5-small` from HF and saved it in cache folder /tmp/tf_transformers_cache/google/mt5-small\n"
     ]
    }
   ],
   "source": [
    "# Check PT conversion\n",
    "\n",
    "!rm -rf /tmp/tf_transformers_cache/google/mt5-small\n",
    "\n",
    "model_name = 'google/mt5-small'\n",
    "model, config = MT5Model.get_model(model_name=model_name, convert_fn_type='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102f679b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f32e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import MT5Tokenizer\n",
    "\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c2a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.encoder_decoder.EncoderDecoder object at 0x7fd661711250> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fd680118c40>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.encoder_decoder.EncoderDecoder object at 0x7fd661711250> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fd680118c40>).\n",
      "INFO:absl:Successful: Model checkpoints matched and loaded from /tmp/tf_transformers_cache/google/mt5-small\n"
     ]
    }
   ],
   "source": [
    "# MT5 text generation without caching\n",
    "text = \"summarize: studies have shown that owning a dog is good for you\"\n",
    "\n",
    "inputs_hf = tokenizer(text, return_tensors='tf')\n",
    "inputs = {}\n",
    "inputs['encoder_input_ids'] = inputs_hf['input_ids']\n",
    "inputs['encoder_input_mask'] = inputs_hf['attention_mask']\n",
    "inputs['decoder_input_ids']  = tf.constant([[0]])\n",
    "\n",
    "predictions_non_auto_regressive = []\n",
    "predictions_prob_non_auto_regressive = []\n",
    "\n",
    "for i in range(10):\n",
    "    outputs = model(inputs)\n",
    "    predicted_ids = tf.cast(tf.expand_dims(tf.argmax(outputs[\"last_token_logits\"], axis=1), 1), tf.int32)\n",
    "    inputs[\"decoder_input_ids\"] = tf.concat([inputs[\"decoder_input_ids\"], predicted_ids], axis=1)\n",
    "    predictions_non_auto_regressive.append(predicted_ids)\n",
    "    predictions_prob_non_auto_regressive.append(\n",
    "        tf.expand_dims(tf.reduce_max(outputs[\"last_token_logits\"], axis=1), 1)\n",
    "    )\n",
    "predictions_non_auto_regressive = tf.concat(predictions_non_auto_regressive, axis=1)\n",
    "predictions_prob_non_auto_regressive = tf.concat(predictions_prob_non_auto_regressive, axis=1)\n",
    "\n",
    "# Text generation with cache\n",
    "model, config = MT5Model.get_model(model_name=model_name, convert_fn_type='pt', use_auto_regressive=True)\n",
    "\n",
    "encoder_input_ids = inputs_hf['input_ids']\n",
    "encoder_input_mask = inputs_hf['attention_mask']\n",
    "\n",
    "batch_size = tf.shape(encoder_input_ids)[0]\n",
    "seq_length = tf.shape(encoder_input_ids)[1]\n",
    "\n",
    "decoder_input_ids  = tf.reshape([0] * batch_size, (batch_size,1))\n",
    "\n",
    "\n",
    "encoder_hidden_dim = config['embedding_size']\n",
    "num_hidden_layers  = config['num_hidden_layers']\n",
    "num_attention_heads = config['num_attention_heads']\n",
    "attention_head_size = config['attention_head_size']\n",
    "\n",
    "encoder_hidden_states = tf.zeros((batch_size, seq_length, encoder_hidden_dim))\n",
    "\n",
    "decoder_all_cache_key = tf.zeros((num_hidden_layers, \n",
    "                                  batch_size, \n",
    "                                  num_attention_heads, \n",
    "                                  seq_length, \n",
    "                                  attention_head_size))\n",
    "decoder_all_cahce_value = tf.zeros((num_hidden_layers, \n",
    "                                  batch_size, \n",
    "                                  num_attention_heads, \n",
    "                                  seq_length, \n",
    "                                  attention_head_size))\n",
    "\n",
    "\n",
    "inputs = {}\n",
    "inputs['encoder_input_ids'] = encoder_input_ids\n",
    "inputs['encoder_input_mask']= encoder_input_mask\n",
    "inputs['decoder_input_ids'] = decoder_input_ids\n",
    "inputs['encoder_hidden_states'] = encoder_hidden_states\n",
    "inputs['decoder_all_cache_key'] = decoder_all_cache_key\n",
    "inputs['decoder_all_cache_value'] = decoder_all_cahce_value\n",
    "\n",
    "predictions_auto_regressive = []\n",
    "predictions_prob_auto_regressive = []\n",
    "\n",
    "for i in range(10):\n",
    "    outputs = model(inputs)\n",
    "    predicted_ids = tf.cast(tf.expand_dims(tf.argmax(outputs[\"last_token_logits\"], axis=1), 1), tf.int32)\n",
    "    inputs[\"decoder_input_ids\"] = predicted_ids\n",
    "    inputs[\"decoder_all_cache_key\"] = outputs[\"decoder_all_cache_key\"]\n",
    "    inputs[\"decoder_all_cache_value\"] = outputs[\"decoder_all_cache_value\"]\n",
    "    inputs[\"encoder_hidden_states\"] = outputs[\"encoder_hidden_states\"]\n",
    "    predictions_auto_regressive.append(predicted_ids)\n",
    "    predictions_prob_auto_regressive.append(\n",
    "        tf.expand_dims(tf.reduce_max(outputs[\"last_token_logits\"], axis=1), 1)\n",
    "    )\n",
    "predictions_auto_regressive = tf.concat(predictions_auto_regressive, axis=1)\n",
    "predictions_prob_auto_regressive = tf.concat(predictions_prob_auto_regressive, axis=1)\n",
    "\n",
    "#----------------------------------------------------------------------------------------#\n",
    "tf.assert_equal(predictions_non_auto_regressive, predictions_auto_regressive)\n",
    "assert(np.allclose(predictions_prob_non_auto_regressive.numpy(), \n",
    "            predictions_prob_auto_regressive.numpy()) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28889355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56734, 147087, 147087, 243511,  14607,  14607,  14607, 138182,\n",
       "         14607, 138182]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_auto_regressive.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d85d4e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as tf_transformers/mt5_encoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_encoder_layer_call_fn, tf_transformers/mt5_decoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_decoder_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1580). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as tf_transformers/mt5_encoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_encoder_layer_call_fn, tf_transformers/mt5_decoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_decoder_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1580). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwbuwkp70/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwbuwkp70/assets\n"
     ]
    }
   ],
   "source": [
    "# Text generation using saved_model with TextDecoder\n",
    "\n",
    "import tempfile\n",
    "import shutil\n",
    "from tf_transformers.text import TextDecoderSeq2Seq\n",
    "\n",
    "text = \"summarize: studies have shown that owning a dog is good for you\"\n",
    "\n",
    "saved_model_dir = tempfile.mkdtemp()\n",
    "model.save_as_serialize_module(saved_model_dir, overwrite=True)\n",
    "\n",
    "loaded   = tf.saved_model.load(saved_model_dir)\n",
    "decoder  = TextDecoderSeq2Seq(\n",
    "    model = loaded, \n",
    "    decoder_start_token_id = 0 # for mt5\n",
    ")\n",
    "\n",
    "inputs_hf = tokenizer(text, return_tensors='tf')\n",
    "inputs = {}\n",
    "inputs['encoder_input_ids'] = inputs_hf['input_ids']\n",
    "inputs['encoder_input_mask'] = inputs_hf['attention_mask']\n",
    "\n",
    "decoder_results = decoder.decode(inputs, \n",
    "               mode='greedy', \n",
    "               max_iterations=10, \n",
    "               eos_id=-100)\n",
    "\n",
    "expected_ids = [[[ 56734, 147087, 147087, 243511,  14607,  14607,  14607, 138182,14607, 138182]]]\n",
    "assert(decoder_results['predicted_ids'].numpy().tolist() == expected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01310221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c66986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as tf_transformers/mt5_encoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_encoder_layer_call_fn, tf_transformers/mt5_decoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_decoder_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1580). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as tf_transformers/mt5_encoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_encoder_layer_call_fn, tf_transformers/mt5_decoder_layer_call_and_return_conditional_losses, tf_transformers/mt5_decoder_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1580). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwbuwkp70/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwbuwkp70/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text generation using saved_model with TextDecoderSerializable\n",
    "\n",
    "import tempfile\n",
    "import shutil\n",
    "from tf_transformers.text import TextDecoderSerializableSeq2Seq\n",
    "\n",
    "\n",
    "loaded   = tf.saved_model.load(saved_model_dir)\n",
    "decoder  = TextDecoderSerializableSeq2Seq(\n",
    "    model = model,\n",
    "    decoder_start_token_id = 0,\n",
    "    max_iterations=10,\n",
    "    mode=\"greedy\",\n",
    "    do_sample=False,\n",
    "    eos_id=-100\n",
    ")\n",
    "\n",
    "# Save\n",
    "decoder_model = decoder.get_model()\n",
    "decoder_model.save_serialized(saved_model_dir, overwrite=True)\n",
    "\n",
    "# Load\n",
    "loaded_decoder   = tf.saved_model.load(saved_model_dir)\n",
    "model_pb_decoder = loaded_decoder.signatures['serving_default']\n",
    "\n",
    "text = \"summarize: studies have shown that owning a dog is good for you\"\n",
    "inputs_hf = tokenizer(text, return_tensors='tf')\n",
    "inputs = {}\n",
    "inputs['encoder_input_ids'] = inputs_hf['input_ids']\n",
    "inputs['encoder_input_mask'] = inputs_hf['attention_mask']\n",
    "\n",
    "\n",
    "decoder_results_serialized = model_pb_decoder(**inputs)\n",
    "\n",
    "np.allclose(decoder_results_serialized['predicted_ids'].numpy(), expected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c93ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e5956ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c896c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
