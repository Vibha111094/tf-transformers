{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tf_transformers.models import ROBERTAEncoder, RobertaModel, AlbertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n"
     ]
    }
   ],
   "source": [
    "# Default configs for the model\n",
    "model_config_dir = '/Users/PRVATE/Documents/tf_transformers/src/tf_transformers/models/model_configs/'\n",
    "\n",
    "model_name = 'roberta_base'\n",
    "config_location = os.path.join(model_config_dir, model_name, 'config.json')\n",
    "config = json.load(open(config_location))\n",
    "# config['num_hidden_layers'] = 1\n",
    "# Always do this\n",
    "\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "encoder_layer = ROBERTAEncoder(config=config,\n",
    "                      name='roberta',\n",
    "                      mask_mode=config['mask_mode'],\n",
    "                      is_training=True,\n",
    "                      use_dropout=False,\n",
    "                      cross_attention_inside_encoder=True,\n",
    "                      )\n",
    "model = encoder_layer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n"
     ]
    }
   ],
   "source": [
    "model_layer, model, config = RobertaModel(model_name='roberta_base',\n",
    "                      is_training=False,\n",
    "                      cross_attention_inside_encoder=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings projected Tensor(\"tf_transformers/albert/lower_embedding_projection/mul_3:0\", shape=(None, None, 128), dtype=float32)\n",
      "Token embeddings projected Tensor(\"tf_transformers/albert/lower_embedding_projection/mul_7:0\", shape=(None, None, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_layer, model, config = AlbertModel(model_name='albert-base-v2',\n",
    "                      is_training=False,\n",
    "                      cross_attention_inside_encoder=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logits = tf.random.uniform((5, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([748, 310, 292, 306, 735])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[412],\n",
       "       [714],\n",
       "       [341],\n",
       "       [311],\n",
       "       [255]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.categorical(model_logits, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.999079  , 0.99765325],\n",
       "       [0.9981979 , 0.9981326 ],\n",
       "       [0.9992883 , 0.9977151 ],\n",
       "       [0.9998293 , 0.9983845 ],\n",
       "       [0.99699914, 0.9968606 ]], dtype=float32)>, indices=<tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
       "array([[748, 484],\n",
       "       [310, 213],\n",
       "       [292, 592],\n",
       "       [306, 241],\n",
       "       [735, 623]], dtype=int32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.top_k(model_logits, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n"
     ]
    }
   ],
   "source": [
    "# Default configs for the model\n",
    "model_config_dir = '/Users/PRVATE/Documents/tf_transformers/src/tf_transformers/models/model_configs/'\n",
    "\n",
    "model_name = 'roberta_base'\n",
    "config_location = os.path.join(model_config_dir, model_name, 'config.json')\n",
    "config = json.load(open(config_location))\n",
    "# config['num_hidden_layers'] = 1\n",
    "# Always do this\n",
    "\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "encoder_layer = ROBERTAEncoder(config=config,\n",
    "                      name='roberta',\n",
    "                      mask_mode=config['mask_mode'],\n",
    "                      is_training=False,\n",
    "                      cross_attention_inside_encoder=True,\n",
    "                      )\n",
    "model_test = encoder_layer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_test.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder_input_ids': <tf.Tensor 'encoder_input_ids_1:0' shape=(None, None) dtype=int32>,\n",
       " 'decoder_input_ids': <tf.Tensor 'decoder_input_ids_1:0' shape=(None, None) dtype=int32>,\n",
       " 'encoder_input_type_ids': <tf.Tensor 'encoder_input_type_ids_1:0' shape=(None, None) dtype=int32>,\n",
       " 'decoder_input_type_ids': <tf.Tensor 'decoder_input_type_ids_1:0' shape=(None, None) dtype=int32>,\n",
       " 'encoder_input_mask': <tf.Tensor 'encoder_input_mask_1:0' shape=(None, None) dtype=int32>,\n",
       " 'decoder_all_cache_key': <tf.Tensor 'decoder_all_cache_key_1:0' shape=(None, None, 12, None, 64) dtype=float32>,\n",
       " 'decoder_all_cache_value': <tf.Tensor 'decoder_all_cache_value_1:0' shape=(None, None, 12, None, 64) dtype=float32>,\n",
       " 'encoder_hidden_states': <tf.Tensor 'encoder_hidden_states_1:0' shape=(None, None, 768) dtype=float32>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder': {'initializer': {'class_name': 'TruncatedNormal',\n",
       "   'config': {'mean': 0.0, 'stddev': 0.02, 'seed': None}},\n",
       "  'is_training': False,\n",
       "  'use_dropout': False,\n",
       "  'batch_size': None,\n",
       "  'sequence_length': None,\n",
       "  'name': 'tf_transformers/roberta',\n",
       "  'use_type_embeddings': True,\n",
       "  'use_positonal_embeddings': True,\n",
       "  'is_decoder': False,\n",
       "  'share_encoder_embeddings': False,\n",
       "  'share_attention_layers': True,\n",
       "  'cross_attention_inside_encoder': True,\n",
       "  'attention_probs_dropout_prob': 0.1,\n",
       "  'hidden_act': 'gelu',\n",
       "  'intermediate_act': 'gelu',\n",
       "  'hidden_dropout_prob': 0.1,\n",
       "  'embedding_size': 768,\n",
       "  'initializer_range': 0.02,\n",
       "  'intermediate_size': 3072,\n",
       "  'max_position_embeddings': 512,\n",
       "  'num_attention_heads': 12,\n",
       "  'num_hidden_layers': 12,\n",
       "  'type_vocab_size': 1,\n",
       "  'vocab_size': 50265,\n",
       "  'layer_norm_epsilon': 1e-05,\n",
       "  'mask_mode': 'user_defined'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "data = datasets.load_from_disk(\"/Users/PRVATE/HUggingFace_Models/dataset/cnn_dailymail/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "train_data = data[\"train\"].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.data import pad_dataset\n",
    "encoder_max_length=512\n",
    "decoder_max_length=64\n",
    "batch_size = 2\n",
    "\n",
    "@pad_dataset\n",
    "def process_data_to_model_inputs(text_list):\n",
    "    \n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]  \n",
    "    inputs = tokenizer(text_list, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "    tokenized = {}\n",
    "    tokenized[\"encoder_input_ids\"] = inputs.input_ids                                                               \n",
    "    tokenized[\"encoder_input_mask\"] = inputs.attention_mask  \n",
    "    tokenized[\"encoder_input_type_ids\"] = tf.zeros_like(inputs.attention_mask).numpy()\n",
    "\n",
    "    return tokenized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = train_data.select(range(2))\n",
    "article_list = [item['article'] for item in list(sample_data)]\n",
    "encoded_inputs = process_data_to_model_inputs(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last token logits tf.Tensor([-45.611828 -41.32108 ], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([2.768261 5.879841], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-4.442688  -2.2368774], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-34.530613 -30.754063], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-9.683073 -7.421894], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-15.290382 -12.106243], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-50.454346 -46.79603 ], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-41.44793 -38.67273], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-4.178528  -2.7922554], shape=(2,), dtype=float32)\n",
      "Last token logits tf.Tensor([-44.15262  -41.173218], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs['decoder_input_ids'] = tf.cast(tf.ones((2, 1)) * 0, tf.int32)\n",
    "encoded_inputs['decoder_input_type_ids'] = tf.cast(tf.ones((2, 1)) * 0, tf.int32)\n",
    "\n",
    "all_ids = []\n",
    "all_probs = []\n",
    "for i in range(10):\n",
    "    result = model(encoded_inputs)\n",
    "    best_id = tf.cast(tf.argmax(result['last_token_logits'], axis=1), tf.int32)\n",
    "    best_prob = tf.reduce_max(result['last_token_logits'], axis=1)\n",
    "    encoded_inputs['decoder_input_ids'] = tf.concat([encoded_inputs['decoder_input_ids'], tf.expand_dims(best_id, axis=1)], axis=1)\n",
    "    encoded_inputs['decoder_input_type_ids'] = tf.concat([encoded_inputs['decoder_input_type_ids'], tf.cast(tf.expand_dims([0,0], axis=1), tf.int32)], axis=1)\n",
    "    all_ids.append(best_id)\n",
    "    all_probs.append(best_prob)\n",
    "    print(\"Last token logits\", tf.reduce_sum(result['last_token_logits'], axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_hidden_states tf.Tensor(-0.00020980835, shape=(), dtype=float32)\n",
    "\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2.7400916, 2.6976557], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.0687551, 3.0307393], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.1849747, 3.1487033], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.241108 , 3.2023928], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.195044, 3.158273], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.123019 , 3.0789971], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.0359914, 2.99756  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.0729923, 3.0340953], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.2192988, 3.1752768], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.1816077, 3.1537046], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Saved model at dummy/ckpt-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.roberta.ROBERTAEncoder object at 0x109325760> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x13c590580>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.roberta.ROBERTAEncoder object at 0x109325760> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x13c590580>).\n",
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "model.save_checkpoint(\"dummy\", overwrite=True)\n",
    "model_test.load_checkpoint(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor([2.7400916 2.6976557], shape=(2,), dtype=float32)\n",
      "1 tf.Tensor([3.0687551 3.0307395], shape=(2,), dtype=float32)\n",
      "2 tf.Tensor([3.1849747 3.148703 ], shape=(2,), dtype=float32)\n",
      "3 tf.Tensor([3.241109  3.2023926], shape=(2,), dtype=float32)\n",
      "4 tf.Tensor([3.1950445 3.1582716], shape=(2,), dtype=float32)\n",
      "5 tf.Tensor([3.1230192 3.0789976], shape=(2,), dtype=float32)\n",
      "6 tf.Tensor([3.0359912 2.9975595], shape=(2,), dtype=float32)\n",
      "7 tf.Tensor([3.0729923 3.034095 ], shape=(2,), dtype=float32)\n",
      "8 tf.Tensor([3.2192986 3.1752765], shape=(2,), dtype=float32)\n",
      "9 tf.Tensor([3.181608  3.1537042], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = process_data_to_model_inputs(article_list)\n",
    "#from tf_transformers.text import TextDecoderSeq2Seq\n",
    "decoder = TextDecoderSeq2Seq(\n",
    "    model = model_test,\n",
    "    decoder_start_token_id = 0,\n",
    "    decoder_input_type_ids = 0\n",
    ")\n",
    "decoder_results = decoder.decode(encoded_inputs, \n",
    "               mode='greedy', \n",
    "               max_iterations=10, \n",
    "               eos_id=2)\n",
    "\n",
    "# Encoder hidden states tf.Tensor(-0.00036621094, shape=(), dtype=float32)\n",
    "# Decoder hidden states tf.Tensor(7.6293945e-06, shape=(), dtype=float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 10), dtype=int64, numpy=\n",
       "array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results['predicted_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization.LayerNormalization object at 0x13cc428e0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization.LayerNormalization object at 0x13cc428e0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x13cc1fd00>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x13cc1fd00>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp/assets\n"
     ]
    }
   ],
   "source": [
    "model_test.save_as_serialize_module(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
