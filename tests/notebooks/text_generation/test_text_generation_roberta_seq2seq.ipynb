{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tf_transformers.models import ROBERTAEncoder, EncoderDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.utils import get_config, validate_model_name\n",
    "\n",
    "allowed_model_names = [\"roberta_base\", \"roberta_large\"]\n",
    "\n",
    "\n",
    "def modelWrapper(model_name, **kwargs):\n",
    "    \"\"\"Wrapper for Model\n",
    "\n",
    "    Args:\n",
    "        model_name ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"roberta\"\n",
    "\n",
    "    model_name = model_name.replace(\"-\", \"_\")  # replace - with _\n",
    "    validate_model_name(model_name, allowed_model_names)\n",
    "    config = get_config(\"tf_transformers.models.model_configs.roberta\", model_name)\n",
    "\n",
    "    if \"is_training\" not in kwargs:\n",
    "        kwargs[\"is_training\"] = False\n",
    "    checkpoint_dir = None\n",
    "    if \"checkpoint_dir\" in kwargs:\n",
    "        checkpoint_dir = kwargs[\"checkpoint_dir\"]\n",
    "        del kwargs[\"checkpoint_dir\"]\n",
    "    kwargs[\"name\"] = name\n",
    "    print(\"Kwargs\", kwargs)\n",
    "    model_layer = ROBERTAEncoder(config, **kwargs)\n",
    "    model = model_layer.get_model()\n",
    "    if checkpoint_dir:\n",
    "        model.load_checkpoint(checkpoint_dir)\n",
    "    return model_layer, model, config\n",
    "\n",
    "\n",
    "from tf_transformers.utils import get_config, validate_model_name, get_model_wrapper\n",
    "from tf_transformers.models import EncoderDecoder\n",
    "from absl import logging\n",
    "\n",
    "logging.set_verbosity(\"INFO\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 768), dtype=float32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x1800621f0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x144e40e20>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x1800621f0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x144e40e20>).\n",
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "model_layer, model, config = EncoderDecoderModel(model_name='roberta_base', \n",
    "                                                 is_training = False,\n",
    "                                                 share_attention_layers=False,\n",
    "                                                 share_encoder_embeddings=True, \n",
    "                                                 pipeline_mode=\"auto-regressive\")\n",
    "model.load_checkpoint(\"/Users/PRVATE/Documents/Tokenizers/tf_xsum_summarizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to                     True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 512), dtype=float32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_layer, model, config = T5Model(model_name='t5-small', is_training=False, pipeline_mode='auto-regressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x1389afbe0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x158cb0dc0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x1389afbe0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x158cb0dc0>).\n",
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "model.load_checkpoint(\"/Users/PRVATE/tf_transformers_models/t5-small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 768), dtype=float32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_layer_test, model_test, config = EncoderDecoderModel(model_name='roberta_base', is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n",
      "Share attention layers False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "encoder_layer = ROBERTAEncoder(config=config['encoder'],\n",
    "                      name='roberta',\n",
    "                      mask_mode='user_defined',\n",
    "                      is_training=False\n",
    "                      )\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "decoder_layer = ROBERTAEncoder(config=config['encoder'],\n",
    "                      name='roberta',\n",
    "                      mask_mode='causal',\n",
    "                      is_training=False,\n",
    "                      is_decoder = True, \n",
    "                      use_mlm_layer = True,\n",
    "                      share_attention_layers = False, \n",
    "                      share_encoder_embeddings = True, \n",
    "                      encoder_embedding_layer=encoder_layer._embedding_layer,\n",
    "                      encoder_type_embedding_layer=encoder_layer._type_embeddings,\n",
    "                      encoder_positional_embedding_layer=encoder_layer._position_embedding_layer\n",
    "                      \n",
    "                              )\n",
    "len(decoder_layer.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_transformers/last_logits_bias:0 (50265,)\n",
      "tf_transformers/roberta/word_embeddings/embeddings:0 (50265, 768)\n",
      "tf_transformers/roberta/type_embeddings/embeddings:0 (1, 768)\n",
      "tf_transformers/roberta/positional_embeddings/embeddings:0 (512, 768)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_0/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_0/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_0/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_0/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_1/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_1/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_1/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_1/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_2/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_2/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_2/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_2/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_3/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_3/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_3/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_3/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_4/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_4/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_4/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_4/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_5/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_5/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_5/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_5/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_6/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_6/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_6/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_6/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_7/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_7/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_7/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_7/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_8/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_8/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_8/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_8/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_9/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_9/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_9/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_9/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_10/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_10/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_10/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_10/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/self_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention/query/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention/query/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention/key/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention/key/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention/value/kernel:0 (768, 12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention/value/bias:0 (12, 64)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention_output/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention_output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/cross_attention_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/intermediate/kernel:0 (768, 3072)\n",
      "tf_transformers/roberta/transformer/layer_11/intermediate/bias:0 (3072,)\n",
      "tf_transformers/roberta/transformer/layer_11/output/kernel:0 (3072, 768)\n",
      "tf_transformers/roberta/transformer/layer_11/output/bias:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/output_layer_norm/gamma:0 (768,)\n",
      "tf_transformers/roberta/transformer/layer_11/output_layer_norm/beta:0 (768,)\n",
      "tf_transformers/roberta/mlm_layer/dense/kernel:0 (768, 768)\n",
      "tf_transformers/roberta/mlm_layer/dense/bias:0 (768,)\n",
      "tf_transformers/roberta/mlm_layer/layer_normalization/gamma:0 (768,)\n",
      "tf_transformers/roberta/mlm_layer/layer_normalization/beta:0 (768,)\n"
     ]
    }
   ],
   "source": [
    "for var in decoder_layer.variables:\n",
    "    print(var.name, var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model2 = EncoderDecoder(encoder=encoder_layer, \n",
    "                       decoder=decoder_layer, \n",
    "                       is_training=True, \n",
    "                       name = 'bert2bertaaa')\n",
    "model2 = model2.get_model()\n",
    "len(model2.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "model2.load_checkpoint(\"/Users/PRVATE/Documents/Tokenizers/tf_xsum_summarizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/PRVATE/Documents/tf_transformers/src/tf_transformers/models/model_configs/roberta_base/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8aa2824fc124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roberta_base'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# config['num_hidden_layers'] = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Always do this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/PRVATE/Documents/tf_transformers/src/tf_transformers/models/model_configs/roberta_base/config.json'"
     ]
    }
   ],
   "source": [
    "# Default configs for the model\n",
    "model_config_dir = '/Users/PRVATE/Documents/tf_transformers/src/tf_transformers/models/model_configs/'\n",
    "\n",
    "model_name = 'roberta_base'\n",
    "config_location = os.path.join(model_config_dir, model_name, 'config.json')\n",
    "config = json.load(open(config_location))\n",
    "# config['num_hidden_layers'] = 1\n",
    "# Always do this\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "encoder_layer = ROBERTAEncoder(config=config,\n",
    "                      name='roberta',\n",
    "                      mask_mode=config['mask_mode'],\n",
    "                      is_training=False\n",
    "                      )\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "decoder_layer = ROBERTAEncoder(config=config,\n",
    "                      name='roberta',\n",
    "                      mask_mode='causal',\n",
    "                      is_training=False,\n",
    "                      is_decoder = True, \n",
    "                      use_mlm_layer = True,\n",
    "                      share_attention_layers = False, \n",
    "                      share_encoder_embeddings = True, \n",
    "                      encoder_embedding_layer=encoder_layer._embedding_layer,\n",
    "                      encoder_type_embedding_layer=encoder_layer._type_embeddings,\n",
    "                      encoder_positional_embedding_layer=encoder_layer._position_embedding_layer\n",
    "                      \n",
    "                              )\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = EncoderDecoder(encoder=encoder_layer, \n",
    "                       decoder=decoder_layer, \n",
    "                       is_training=True, \n",
    "                       name = 'bert2bert')\n",
    "model = model.get_model()\n",
    "model.load_checkpoint(\"/Users/PRVATE/Documents/Tokenizers/tf_xsum_summarizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder': {'initializer': {'class_name': 'TruncatedNormal',\n",
       "   'config': {'mean': 0.0, 'stddev': 0.02, 'seed': None}},\n",
       "  'is_training': True,\n",
       "  'use_dropout': False,\n",
       "  'batch_size': None,\n",
       "  'sequence_length': None,\n",
       "  'name': 'tf_transformers/roberta',\n",
       "  'use_type_embeddings': True,\n",
       "  'use_positonal_embeddings': True,\n",
       "  'is_decoder': False,\n",
       "  'share_encoder_embeddings': False,\n",
       "  'share_attention_layers': True,\n",
       "  'cross_attention_inside_encoder': False,\n",
       "  'attention_probs_dropout_prob': 0.1,\n",
       "  'hidden_act': 'gelu',\n",
       "  'intermediate_act': 'gelu',\n",
       "  'hidden_dropout_prob': 0.1,\n",
       "  'embedding_size': 768,\n",
       "  'initializer_range': 0.02,\n",
       "  'intermediate_size': 3072,\n",
       "  'max_position_embeddings': 512,\n",
       "  'num_attention_heads': 12,\n",
       "  'num_hidden_layers': 12,\n",
       "  'type_vocab_size': 1,\n",
       "  'vocab_size': 50265,\n",
       "  'layer_norm_epsilon': 1e-05,\n",
       "  'mask_mode': 'user_defined'},\n",
       " 'decoder': {'initializer': {'class_name': 'TruncatedNormal',\n",
       "   'config': {'mean': 0.0, 'stddev': 0.02, 'seed': None}},\n",
       "  'is_training': True,\n",
       "  'use_dropout': False,\n",
       "  'batch_size': None,\n",
       "  'sequence_length': None,\n",
       "  'name': 'tf_transformers/roberta',\n",
       "  'use_type_embeddings': True,\n",
       "  'use_positonal_embeddings': True,\n",
       "  'is_decoder': True,\n",
       "  'share_encoder_embeddings': True,\n",
       "  'share_attention_layers': False,\n",
       "  'cross_attention_inside_encoder': False,\n",
       "  'attention_probs_dropout_prob': 0.1,\n",
       "  'hidden_act': 'gelu',\n",
       "  'intermediate_act': 'gelu',\n",
       "  'hidden_dropout_prob': 0.1,\n",
       "  'embedding_size': 768,\n",
       "  'initializer_range': 0.02,\n",
       "  'intermediate_size': 3072,\n",
       "  'max_position_embeddings': 512,\n",
       "  'num_attention_heads': 12,\n",
       "  'num_hidden_layers': 12,\n",
       "  'type_vocab_size': 1,\n",
       "  'vocab_size': 50265,\n",
       "  'layer_norm_epsilon': 1e-05,\n",
       "  'mask_mode': 'user_defined'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 768), dtype=float32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_type_ids ---> Tensor(\"decoder_input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 12, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 768), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x151e16c40> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x14ef6df70>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x151e16c40> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x14ef6df70>).\n",
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "# Default configs for the model\n",
    "model_config_dir = '/Users/PRVATE/Documents/tf_transformers/src/tf_transformers/models/model_configs/'\n",
    "\n",
    "model_name = 'roberta_base'\n",
    "config_location = os.path.join(model_config_dir, model_name, 'config.json')\n",
    "config = json.load(open(config_location))\n",
    "# config['num_hidden_layers'] = 1\n",
    "# Always do this\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "encoder_layer = ROBERTAEncoder(config=config,\n",
    "                      name='roberta',\n",
    "                      mask_mode=config['mask_mode'],\n",
    "                      is_training=False\n",
    "                      )\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "decoder_layer = ROBERTAEncoder(config=config,\n",
    "                      name='roberta',\n",
    "                      mask_mode='causal',\n",
    "                      is_training=False,\n",
    "                      is_decoder = True,\n",
    "                      pipeline_mode='auto-regressive',\n",
    "                      use_mlm_layer = True,\n",
    "                      share_attention_layers = False, \n",
    "                      share_encoder_embeddings = True, \n",
    "                      encoder_embedding_layer=encoder_layer._embedding_layer,\n",
    "                      encoder_type_embedding_layer=encoder_layer._type_embeddings,\n",
    "                      encoder_positional_embedding_layer=encoder_layer._position_embedding_layer\n",
    "                      \n",
    "                              )\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model_test = EncoderDecoder(encoder=encoder_layer, \n",
    "                       decoder=decoder_layer, \n",
    "                       is_training=False, \n",
    "                       name = 'bert2bert')\n",
    "model_test = model_test.get_model()\n",
    "model_test.load_checkpoint(\"/Users/PRVATE/Documents/Tokenizers/tf_xsum_summarizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "data = datasets.load_from_disk(\"/Users/PRVATE/HUggingFace_Models/dataset/cnn_dailymail/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "train_data = data[\"train\"].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.data import pad_dataset\n",
    "encoder_max_length=512\n",
    "decoder_max_length=64\n",
    "batch_size = 2\n",
    "\n",
    "@pad_dataset\n",
    "def process_data_to_model_inputs(text_list):\n",
    "    \n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]  \n",
    "    inputs = tokenizer(text_list, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "    tokenized = {}\n",
    "    tokenized[\"encoder_input_ids\"] = inputs.input_ids                                                               \n",
    "    tokenized[\"encoder_input_mask\"] = inputs.attention_mask  \n",
    "    tokenized[\"encoder_input_type_ids\"] = tf.zeros_like(inputs.attention_mask).numpy()\n",
    "\n",
    "    return tokenized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = train_data.select(range(2))\n",
    "article_list = [item['article'] for item in list(sample_data)]\n",
    "encoded_inputs = process_data_to_model_inputs(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Saved model at temp/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "model_test.save_checkpoint(\"temp\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization.LayerNormalization object at 0x151e4afa0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization.LayerNormalization object at 0x151e4afa0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x151e5af70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x151e5af70>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/PRVATE/anaconda3/envs/venv_tf_transformers/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp_pb_module/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp_pb_module/assets\n"
     ]
    }
   ],
   "source": [
    "model_test.save_as_serialize_module(\"temp_pb_module/\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(\"temp_pb_module/\")\n",
    "model_pb = loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.text import TextDecoderSeq2Seq\n",
    "decoder = TextDecoderSeq2Seq(\n",
    "    model = model_test,\n",
    "    decoder_start_token_id = 0,\n",
    "    decoder_input_type_ids = 0\n",
    ")\n",
    "\n",
    "# decoder_results = decoder.decode(encoded_inputs, \n",
    "#                mode='beam', \n",
    "#                beam_size=3,\n",
    "#                max_iterations=64, \n",
    "#                eos_id=2)\n",
    "decoder_results = decoder.decode(encoded_inputs, \n",
    "               mode='top_k_top_p', \n",
    "               top_k = 35,\n",
    "               top_p =0.55,\n",
    "               num_return_sequences=3,\n",
    "               max_iterations=64, \n",
    "               eos_id=2)\n",
    "# decoder_results = decoder.decode(encoded_inputs, \n",
    "#                mode='greedy', \n",
    "#                max_iterations=64, \n",
    "#                eos_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 27), dtype=int32, numpy=\n",
       "array([[[ 6517,  1284,    34,   553,  1148,     7,  2625,   549,     5,\n",
       "           382,   197,   304,   831,   814,   136,  1854,   114,    24,\n",
       "            16,    45,  4968,    31,   634,  4747,  2398,     4,     2],\n",
       "        [ 6517,  1284,    34,   553,  1148,     7,  2625,   549,     5,\n",
       "           382,   197,   304,   831,   814,   136,  1854,   114,    24,\n",
       "            16,    45,  4968,    31,   634,  4747,  2398,     4,     2],\n",
       "        [ 6517,  1284,    34,   553,  1148,     7,  2625,   549,     5,\n",
       "           382,   197,   304,   831,   814,   136,  1854,   114,    24,\n",
       "            16,    45,  4968,    31,   634,  4747,  2398,     4,     2]],\n",
       "\n",
       "       [[  133,   232,    18,   144,  1800,  4131,    33,   351,  1637,\n",
       "         10214,    11,     5,   604,    18,   727,   119, 12937,    23,\n",
       "             5,   623,  8641,    11,  3467,     4,     2,     1,     1],\n",
       "        [  133,   232,    18,   144,  1800,  4131,    33,   351,  1637,\n",
       "         10214,    11,     5,   604,    18,   727,   119, 12937,    23,\n",
       "             5,   623,  8641,    11,  3467,     4,     2,     1,     1],\n",
       "        [  133,   232,    18,   144,  1800,  4131,    33,   351,  1637,\n",
       "         10214,    11,     5,   604,    18,   727,   119, 12937,    23,\n",
       "             5,   623,  8641,    11,  3467,     4,     2,     1,     1]]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results['predicted_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([25, 25, 25, 23, 23, 23], dtype=int32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results['matched_eos_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President Barack Obama has asked Congress to debate whether the US should use military action against Syria if it fails to stop the chemical weapons attack.</s><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(decoder_results['predicted_ids'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Great Britain won gold medals at the World Athletics Championships in Moscow on Sunday, with the men's 100m relay team winning gold.</s><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(decoder_results['predicted_ids'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([27, 27, 28, 26, 30, 32], dtype=int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results['matched_eos_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_layer = TextDecoderSerializableSeq2Seq(\n",
    "#     model = model_test,\n",
    "#     decoder_start_token_id = 0,\n",
    "#     decoder_input_type_ids = 0,\n",
    "#     max_iterations=None,\n",
    "#     mode=\"greedy\",\n",
    "#     do_sample=False,\n",
    "#     eos_id=2,\n",
    "# )\n",
    "# # Convert whole operation to a model\n",
    "# decoder_model  = decoder_layer.get_model()\n",
    "\n",
    "\n",
    "# decoder_layer = TextDecoderSerializableSeq2Seq(\n",
    "#     model = model_test,\n",
    "#     decoder_start_token_id = 0,\n",
    "#     decoder_input_type_ids = 0,\n",
    "#     max_iterations=None,\n",
    "#     mode=\"beam\",\n",
    "#     beam_size=3,\n",
    "#     do_sample=False,\n",
    "#     eos_id=2,\n",
    "# )\n",
    "# # Convert whole operation to a model\n",
    "# decoder_model  = decoder_layer.get_model()\n",
    "\n",
    "decoder_layer = TextDecoderSerializableSeq2Seq(\n",
    "    model = model_test,\n",
    "    decoder_start_token_id = 0,\n",
    "    decoder_input_type_ids = 0,\n",
    "    max_iterations=None,\n",
    "    mode=\"top_k_top_p\",\n",
    "    top_k = 35, \n",
    "    top_p = 0.55,\n",
    "    num_return_sequences=3,\n",
    "    do_sample=False,\n",
    "    eos_id=2,\n",
    ")\n",
    "# Convert whole operation to a model\n",
    "decoder_model  = decoder_layer.get_model()\n",
    "\n",
    "# decoder_module = LegacyModule(decoder_model)\n",
    "# decoder_module.save(saved_model_dir_strategy)\n",
    "# print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs_copy = encoded_inputs.copy()\n",
    "encoded_inputs_copy['iterations'] = tf.constant([[64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_results_serialized = decoder_model(encoded_inputs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([25, 25, 25, 23, 23, 23], dtype=int32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results['matched_eos_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([25, 25, 25, 23, 23, 23], dtype=int32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results_serialized['matched_eos_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.assert_equal(decoder_results['predicted_ids'], decoder_results_serialized['predicted_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
