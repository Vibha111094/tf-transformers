{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13a29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/TF_NEW/tf-transformers/src/\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from tf_transformers.models import BertModel\n",
    "from tf_transformers.core import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5ddcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c1357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f87f859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "num_gpus = 1\n",
    "trainer = Trainer(distribution_strategy=\"mirrored\", \n",
    "                 num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77e0b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:absl:Successful: Model checkpoints matched and loaded from /tmp/tf_transformers_cache/bert-base-cased/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "def get_model():\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "    return model\n",
    "with trainer.distribution_strategy.scope():\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f40c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. mirrored Strategy (normal batch and distributed batch)\n",
    "# 2. mirrored Strategy (uneven batch)\n",
    "# 3. mirrored Strategy (less batch)\n",
    "# 4. off Strategy\n",
    "# 5. one device Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fe659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d450ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do a tqdm on number of examples = 1000\n",
    "\n",
    "num_examples = 10001\n",
    "batch_size = 64\n",
    "sequence_length = 128\n",
    "\n",
    "input_ids = tf.random.uniform(minval=0, maxval=3000, shape=(num_examples, sequence_length), dtype=tf.int32)\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.zeros_like(input_ids)\n",
    "\n",
    "ds = {\"input_ids\": input_ids, \"input_mask\": input_mask, \"input_type_ids\": input_type_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01c02c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(ds).batch(batch_size, drop_remainder=False)\n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04f119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4040c092",
   "metadata": {},
   "source": [
    "### Test num_gpus=1 on dataset and dataset distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c45160d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:36<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset iter\n",
    "for (batch_inputs) in tqdm.tqdm(dataset):\n",
    "    outputs = model(batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "292d12ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:18,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset distributed iter\n",
    "for (batch_inputs) in tqdm.tqdm(dataset_distributed):\n",
    "    outputs = model(batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1a115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "281e08fa",
   "metadata": {},
   "source": [
    "### Test num_gpus=2 on dataset and dataset distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c737e4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "You are using a model of type bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:absl:Successful: Model checkpoints matched and loaded from /tmp/tf_transformers_cache/bert-base-cased/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(distribution_strategy=\"mirrored\", \n",
    "                 num_gpus=2)\n",
    "# Define Model\n",
    "def get_model():\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "    return model\n",
    "with trainer.distribution_strategy.scope():\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "484cc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(ds).batch(batch_size, drop_remainder=False)\n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "410563b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:18<00:00,  4.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset iter (Single GPU usage only)\n",
    "for (batch_inputs) in tqdm.tqdm(dataset):\n",
    "    outputs = model(batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dce54360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:46,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset iter\n",
    "\n",
    "@tf.function\n",
    "def step_call(inputs):\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def unwrap_prereplica(output_dict):\n",
    "    result = {}\n",
    "    for key, per_replica_tensor in output_dict.items():\n",
    "        results_tuple = per_replica_tensor.values\n",
    "        # concatanate over row axis\n",
    "        result[key] = tf.concat(results_tuple, axis=0)\n",
    "    return result\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(ds).batch( batch_size, drop_remainder=False)\n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)\n",
    "for (batch_inputs) in tqdm.tqdm(dataset_distributed):\n",
    "    outputs = trainer.distribution_strategy.run(step_call, args=(batch_inputs,))\n",
    "    outputs = unwrap_prereplica(outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a947ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbffdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2d3617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:57,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset iter (Double batch size)\n",
    "\n",
    "@tf.function\n",
    "def step_call(inputs):\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def unwrap_prereplica(output_dict):\n",
    "    result = {}\n",
    "    for key, per_replica_tensor in output_dict.items():\n",
    "        results_tuple = per_replica_tensor.values\n",
    "        # concatanate over row axis\n",
    "        result[key] = tf.concat(results_tuple, axis=0)\n",
    "    return result\n",
    "\n",
    "# Double batch size for 2 GPUs\n",
    "dataset = tf.data.Dataset.from_tensor_slices(ds).batch(2* batch_size, drop_remainder=False)\n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)\n",
    "for (batch_inputs) in tqdm.tqdm(dataset_distributed):\n",
    "    outputs = trainer.distribution_strategy.run(step_call, args=(batch_inputs,))\n",
    "    outputs = unwrap_prereplica(outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5003001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4124da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:38,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset iter (Double batch size)\n",
    "\n",
    "@tf.function\n",
    "def step_call(inputs):\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def unwrap_prereplica(output_dict):\n",
    "    result = {}\n",
    "    for key, per_replica_tensor in output_dict.items():\n",
    "        results_tuple = per_replica_tensor.values\n",
    "        # concatanate over row axis\n",
    "        result[key] = tf.concat(results_tuple, axis=0)\n",
    "    return result\n",
    "\n",
    "# Double batch size for 2 GPUs\n",
    "dataset = tf.data.Dataset.from_tensor_slices(ds).batch(2* batch_size, drop_remainder=False)\n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)\n",
    "for (batch_inputs) in tqdm.tqdm(dataset_distributed):\n",
    "    outputs = trainer.distribution_strategy.run(step_call, args=(batch_inputs,))\n",
    "    #outputs = unwrap_prereplica(outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac09d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae0b4b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:40,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset iter (Double batch size)\n",
    "\n",
    "@tf.function\n",
    "def step_call(inputs):\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def unwrap_prereplica(output_dict):\n",
    "    result = {}\n",
    "    for key, per_replica_tensor in output_dict.items():\n",
    "        results_tuple = per_replica_tensor.values\n",
    "        # concatanate over row axis\n",
    "        result[key] = tf.concat(results_tuple, axis=0)\n",
    "    return result\n",
    "\n",
    "# Double batch size for 2 GPUs\n",
    "dataset = tf.data.Dataset.from_tensor_slices(ds).batch(3* batch_size, drop_remainder=False)\n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)\n",
    "for (batch_inputs) in tqdm.tqdm(dataset_distributed):\n",
    "    outputs = trainer.distribution_strategy.run(step_call, args=(batch_inputs,))\n",
    "    #outputs = unwrap_prereplica(outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8cf41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01e835bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, type_embeddings_layer_call_fn, type_embeddings_layer_call_and_return_conditional_losses, positional_embeddings_layer_call_fn while saving (showing 5 of 890). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, type_embeddings_layer_call_fn, type_embeddings_layer_call_and_return_conditional_losses, positional_embeddings_layer_call_fn while saving (showing 5 of 890). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6xq2r3jr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6xq2r3jr/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model as saved model and load\n",
    "\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "saved_model_dir = tempfile.mkdtemp()\n",
    "model.save_as_serialize_module(saved_model_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8dbac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "205a38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model inside strategy\n",
    "del model\n",
    "\n",
    "@tf.function \n",
    "def step_call_inference(inputs):\n",
    "    input_ids = inputs['input_ids']\n",
    "    input_mask = inputs['input_mask']\n",
    "    input_type_ids = inputs['input_type_ids']\n",
    "    \n",
    "    outputs = inference_func(input_ids=input_ids,\n",
    "                   input_mask=input_mask,\n",
    "                   input_type_ids=input_type_ids)\n",
    "    return outputs\n",
    "\n",
    "with trainer.distribution_strategy.scope():\n",
    "    loaded = tf.saved_model.load(saved_model_dir)\n",
    "    inference_func = loaded.signatures['serving_default']\n",
    "    \n",
    "dataset_distributed = trainer.distribution_strategy.experimental_distribute_dataset(dataset)\n",
    "for (batch_inputs) in tqdm.tqdm(dataset_distributed):\n",
    "    outputs = trainer.distribution_strategy.run(step_call_inference, args=(batch_inputs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3ad3fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f7f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd40a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
