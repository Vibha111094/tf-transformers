{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rWvi3WhdQob",
        "outputId": "826b55c1-a654-4908-f9d1-b897285a782e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 32.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 25.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 19.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 14.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 16.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 16.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 15.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 16.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 16.7MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 16.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 16.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 16.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 16.7MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 16.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 16.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 16.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 57.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 61.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a98ff3337cdb67aa967eaa08f5eb697e755ff8e081f0cff1411c1e0a5de8b1b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtjmOfq0d6db"
      },
      "source": [
        "# Benchmarking with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpFRjm90dv77"
      },
      "source": [
        "from transformers import TFGPT2LMHeadModel\n",
        "model_name = 'gpt2'\n",
        "model = TFGPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx8oXihpfPF4",
        "outputId": "3d25636f-db90-4871-ae6a-0d002f169e44"
      },
      "source": [
        "# Move to gpu\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assigned\n",
            "Cuda Avaliable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKzd2Xs2ejLM"
      },
      "source": [
        "## Greedy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYgRqYRGltg7"
      },
      "source": [
        "from functools import wraps\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "average_runs = 4\n",
        "\n",
        "def timeit(my_func):\n",
        "    @wraps(my_func)\n",
        "    def timed(*args, **kw):\n",
        "        time_list = []\n",
        "        for i in range(3):\n",
        "          tstart = time.time()\n",
        "          output = my_func(*args, **kw)\n",
        "          tend = time.time()\n",
        "          time_taken = tend-tstart\n",
        "          time_list.append((tend - tstart))\n",
        "          \n",
        "        return np.mean(time_list[1:]) # return last 3\n",
        "    return timed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQCN4u0eeQqo",
        "outputId": "5f72606a-d5d6-4a10-cf4e-b9a04d738b32"
      },
      "source": [
        "timing_results = {}\n",
        "batch_size_list = [1, 3, 5, 10]\n",
        "max_seq_length_list = [15, 25, 50, 100, 150]\n",
        "\n",
        "@timeit\n",
        "def call_greedy(input_tensor, length):\n",
        "  result_greedy = model.generate(input_tensor, max_length=length, early_stopping=False)\n",
        "  return result_greedy\n",
        "\n",
        "minval = 1\n",
        "maxval = 50256\n",
        "input_tensor_length = 100\n",
        "\n",
        "timing_holder = {}\n",
        "for batch in batch_size_list:\n",
        "  for sequence_length in max_seq_length_list:\n",
        "    input_tensor = tf.random.uniform(minval=minval, maxval=maxval, shape=(batch,input_tensor_length), dtype=tf.int32)\n",
        "    # because we need to genrate that much tokens from input_tensor_length\n",
        "    average_time_taken = call_greedy(input_tensor, input_tensor_length + sequence_length)\n",
        "    #timing_holder['{}_{}'.format(batch, sequence_length)] = average_time_taken\n",
        "    timing_holder[(batch, sequence_length)] = average_time_taken\n",
        "    print(\"Done batch_size {} sequence length {}\".format(batch, sequence_length))\n",
        "\n",
        "    \n",
        "timing_results['greedy'] = timing_holder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 1 sequence length 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 1 sequence length 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 1 sequence length 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 1 sequence length 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 1 sequence length 150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 3 sequence length 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 3 sequence length 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 3 sequence length 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 3 sequence length 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 3 sequence length 150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 5 sequence length 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 5 sequence length 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 5 sequence length 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 5 sequence length 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 5 sequence length 150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 10 sequence length 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 10 sequence length 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 10 sequence length 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 10 sequence length 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done batch_size 10 sequence length 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VovpEoPhwq1u"
      },
      "source": [
        "# Beam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S-hEzVzgDTc"
      },
      "source": [
        "batch_size_list = [1, 3, 5, 10]\n",
        "max_seq_length_list = [15, 25, 50, 100, 150]\n",
        "beam_list = [1, 2, 5, 7, 10]\n",
        "\n",
        "@timeit\n",
        "def call_beam(input_tensor, length, beam):\n",
        "  result = model.generate(input_tensor, max_length=length, num_beams=beam, early_stopping=False)\n",
        "  return result\n",
        "\n",
        "minval = 1\n",
        "maxval = 50256\n",
        "input_tensor_length = 100\n",
        "\n",
        "timing_holder = {}\n",
        "for batch in batch_size_list:\n",
        "  for sequence_length in max_seq_length_list:\n",
        "    for beam in beam_list:\n",
        "      input_tensor = tf.random.uniform(minval=minval, maxval=maxval, shape=(batch,input_tensor_length), dtype=tf.int32)\n",
        "      # because we need to genrate that much tokens from input_tensor_length\n",
        "      average_time_taken = call_beam(input_tensor, input_tensor_length + sequence_length, beam)\n",
        "      #timing_holder['{}_{}'.format(batch, sequence_length)] = average_time_taken\n",
        "      timing_holder[(batch, sequence_length, beam)] = average_time_taken\n",
        "      print(\"Done batch_size {} sequence length {}\".format(batch, sequence_length))\n",
        "\n",
        "    \n",
        "timing_results['beam'] = timing_holder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovZfdICfyO1V"
      },
      "source": [
        "## Top K Top P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPGmc21PitMu"
      },
      "source": [
        "batch_size_list = [1, 3, 5, 10]\n",
        "max_seq_length_list = [15, 25, 50, 100, 150]\n",
        "num_return_sequence_list = [1, 2, 5, 7, 10]\n",
        "\n",
        "@timeit\n",
        "def call_top_k_top_p(input_tensor, length, return_sequence):\n",
        "  result = model.generate(input_tensor, max_length=length, num_return_sequences=return_sequence, top_p=0.75, \n",
        "    top_k=25, do_sample=True, early_stopping=False)\n",
        "  return result\n",
        "\n",
        "minval = 1\n",
        "maxval = 50256\n",
        "input_tensor_length = 100\n",
        "\n",
        "timing_holder = {}\n",
        "for batch in batch_size_list:\n",
        "  for sequence_length in max_seq_length_list:\n",
        "    for num_return_sequence in num_return_sequence_list:\n",
        "      input_tensor = tf.random.uniform(minval=minval, maxval=maxval, shape=(batch,input_tensor_length), dtype=tf.int32)\n",
        "      # because we need to genrate that much tokens from input_tensor_length\n",
        "      average_time_taken = call_top_k_top_p(input_tensor, input_tensor_length + sequence_length, num_return_sequence)\n",
        "      #timing_holder['{}_{}'.format(batch, sequence_length)] = average_time_taken\n",
        "      timing_holder[(batch, sequence_length, num_return_sequence)] = average_time_taken\n",
        "      print(\"Done batch_size {} sequence length {}\".format(batch, sequence_length))\n",
        "\n",
        "    \n",
        "timing_results['top_k_top_p'] = timing_holder\n",
        "\n",
        "import pickle\n",
        "with open(\"tensorflow_gpt2_benchmark.pkl\", \"wb\") as f:\n",
        "    pickle.dump(timing_results, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANmPzVqciu_E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
