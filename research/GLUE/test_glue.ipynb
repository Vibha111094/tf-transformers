{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d2f830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nameserver 172.16.0.10\n",
      "search fmr-a642163.svc.gpu-cluster.local svc.gpu-cluster.local gpu-cluster.local fmr.com\n",
      "options ndots:5\n",
      "cat: /home/jovyan/.wgetrcb: No such file or directory\n",
      "10.239.228.20:8000\n",
      "10.239.228.20:8000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['NO_PROXY'] = '169.254.169.254'\n",
    "\n",
    "os.environ['HTTP_PROXY'] = '10.239.228.20:8000'\n",
    "\n",
    "os.environ['HTTPS_PROXY'] = '10.239.228.20:8000'\n",
    "\n",
    "!cat /etc/resolv.conf\n",
    "\n",
    "!cat ~/.wgetrcb\n",
    "\n",
    "!echo \"use_proxy=yes\\nhttp_proxy=http.proxy.fmr.com:8000\\nhttps_proxy=http.proxy.fmr.com:8000\" > ~/.wgetrc\n",
    "\n",
    " \n",
    "\n",
    "#cat ~/.wgetrc\n",
    "\n",
    "!echo $HTTP_PROXY\n",
    "\n",
    "!echo $HTTPS_PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd623f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/TF_NEW/tf-transformers/src/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ef792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0f4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import glob\n",
    "import datasets\n",
    "import shutil\n",
    "\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from tf_transformers.data import TFReader, TFWriter\n",
    "from model import get_model, get_tokenizer, get_optimizer, get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506894e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca963cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'train_batch_size': 32, 'eval_batch_size': 64, 'take_sample': True, 'max_seq_length': 128}, 'trainer': {'type': 'gpu', 'dtype': 'fp32', 'num_gpus': 2, 'tpu_address': None, 'epochs': 3, 'strategy': 'mirrored'}, 'optimizer': {'learning_rate': 2e-05, 'loss_type': None}, 'glue': {'task': {'name': 'mrpc'}, 'data': {'name': 'mrpc'}}}\n"
     ]
    }
   ],
   "source": [
    "with initialize(config_path=\"conf/\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[\"data.take_sample=true\", \"+glue=mrpc\"])\n",
    "    print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffd728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e04b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps\n",
    "\n",
    "# 1. Download the data\n",
    "# 2. Prepare TFRecords\n",
    "# 3. Read TFrecords to tf.data\n",
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7474312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3077591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to features using specific length\n",
    "# into a temp dir (and log it as well for monitoring)\n",
    "\n",
    "def get_dataset(data, batch_size, tokenizer, max_seq_length, mode, tfrecord_dir, take_sample=False):\n",
    "    \n",
    "    if mode not in [\"train\", \"eval\"]:\n",
    "        raise ValueError(\"Inavlid mode `{}` specified. Available mode is ['train', 'eval']\".format(mode))\n",
    "    \n",
    "    def get_tfrecord_example(data):\n",
    "        result = {}\n",
    "        for f in data:\n",
    "            input_ids_s1 = [tokenizer.cls_token] + tokenizer.tokenize(f['sentence1'])[: max_seq_length-2] + [tokenizer.sep_token] # -2 to add CLS and SEP\n",
    "            input_ids_s1 = tokenizer.convert_tokens_to_ids(input_ids_s1)\n",
    "            input_type_ids_s1 = [0] * len(input_ids_s1) # 0 for s1\n",
    "\n",
    "            input_ids_s2 = tokenizer.tokenize(f['sentence2'])[: max_seq_length-1] + [tokenizer.sep_token] # -1 to add SEP\n",
    "            input_ids_s2 = tokenizer.convert_tokens_to_ids(input_ids_s2)\n",
    "            input_type_ids_s2 = [1] * len(input_ids_s2)\n",
    "            \n",
    "            # concatanate two sentences\n",
    "            input_ids =  input_ids_s1 + input_ids_s2\n",
    "            input_type_ids = input_type_ids_s1 + input_type_ids_s2\n",
    "            input_mask = [1] * len(input_ids) # 1 for s2\n",
    "            \n",
    "            result = {}\n",
    "            result['input_ids'] = input_ids\n",
    "            result['input_mask'] = input_mask\n",
    "            result['input_type_ids'] = input_type_ids\n",
    "\n",
    "            result['labels'] = f['label']\n",
    "            yield result\n",
    "            \n",
    "    schema = {\n",
    "        \"input_ids\": (\"var_len\", \"int\"),\n",
    "        \"input_mask\": (\"var_len\", \"int\"),\n",
    "        \"input_type_ids\": (\"var_len\", \"int\"),\n",
    "        \"labels\": (\"var_len\", \"int\"),\n",
    "    }\n",
    "    \n",
    "    # Create a temp dir\n",
    "    if mode == \"train\":\n",
    "        # Write tf records\n",
    "        train_data_dir = os.path.join(tfrecord_dir,\"train\")        \n",
    "        tfrecord_filename = 'mrpc'\n",
    "        tfwriter = TFWriter(schema=schema, \n",
    "                            file_name=tfrecord_filename, \n",
    "                            model_dir=train_data_dir,\n",
    "                            tag='train',\n",
    "                            overwrite=False\n",
    "                     )\n",
    "        data_train = data['train']\n",
    "        # Take sample\n",
    "        if take_sample:\n",
    "            data_train = data_train.select(range(500))\n",
    "            \n",
    "        tfwriter.process(parse_fn=get_tfrecord_example(data_train))\n",
    "        \n",
    "        # Read tfrecord to dataset\n",
    "        schema = json.load(open(\"{}/schema.json\".format(train_data_dir)))\n",
    "        stats  = json.load(open('{}/stats.json'.format(train_data_dir)))\n",
    "        all_files = glob.glob(\"{}/*.tfrecord\".format(train_data_dir))\n",
    "        tf_reader = TFReader(schema=schema, \n",
    "                            tfrecord_files=all_files)\n",
    "\n",
    "        x_keys = ['input_ids', 'input_type_ids', 'input_mask']\n",
    "        y_keys = ['labels']\n",
    "        train_dataset = tf_reader.read_record(auto_batch=True, \n",
    "                                           keys=x_keys,\n",
    "                                           batch_size=batch_size, \n",
    "                                           x_keys = x_keys, \n",
    "                                           y_keys = y_keys,\n",
    "                                           shuffle=True, \n",
    "                                           drop_remainder=True\n",
    "                                          )\n",
    "        return train_dataset, stats['total_records']\n",
    "    if mode == \"eval\":\n",
    "        # Write tfrecords\n",
    "        eval_data_dir = os.path.join(tfrecord_dir,\"eval\")\n",
    "        tfrecord_filename = 'mrpc'\n",
    "        tfwriter = TFWriter(schema=schema, \n",
    "                            file_name=tfrecord_filename, \n",
    "                            model_dir=eval_data_dir,\n",
    "                            tag='dev',\n",
    "                            overwrite=False\n",
    "                            )\n",
    "        data_eval = data['validation']\n",
    "        # Take sample\n",
    "        if take_sample:\n",
    "            data_eval = data_eval.select(range(500))\n",
    "        tfwriter.process(parse_fn=get_tfrecord_example(data_eval))\n",
    "        \n",
    "        \n",
    "        # Read tfrecord to dataset\n",
    "        schema = json.load(open(\"{}/schema.json\".format(eval_data_dir)))\n",
    "        stats  = json.load(open('{}/stats.json'.format(eval_data_dir)))\n",
    "        all_files = glob.glob(\"{}/*.tfrecord\".format(eval_data_dir))\n",
    "        tf_reader = TFReader(schema=schema, \n",
    "                            tfrecord_files=all_files)\n",
    "\n",
    "        x_keys = ['input_ids', 'input_type_ids', 'input_mask']\n",
    "        y_keys = ['labels']\n",
    "        eval_dataset = tf_reader.read_record(auto_batch=True, \n",
    "                                           keys=x_keys,\n",
    "                                           batch_size=batch_size, \n",
    "                                           x_keys = x_keys, \n",
    "                                           y_keys = y_keys,\n",
    "                                           shuffle=False, \n",
    "                                           drop_remainder=False\n",
    "                                          )\n",
    "        return eval_dataset, stats['total_records']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bdab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f213e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f83593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'train_batch_size': 32, 'eval_batch_size': 64, 'take_sample': True, 'max_seq_length': 128}, 'trainer': {'type': 'gpu', 'dtype': 'fp32', 'num_gpus': 2, 'tpu_address': None, 'epochs': 3, 'strategy': 'mirrored'}, 'optimizer': {'learning_rate': 2e-05, 'loss_type': None}, 'glue': {'task': {'name': 'mrpc'}, 'data': {'name': 'mrpc'}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10419221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f9a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909c9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data specific configuration\n",
    "max_seq_len = cfg.data.max_seq_length\n",
    "take_sample = cfg.data.take_sample\n",
    "max_seq_length = cfg.data.max_seq_length\n",
    "train_batch_size = cfg.data.train_batch_size\n",
    "eval_batch_size  = cfg.data.eval_batch_size\n",
    "\n",
    "# Trainer specifics\n",
    "device = cfg.trainer.type\n",
    "num_gpus = cfg.trainer.num_gpus\n",
    "tpu_address = cfg.trainer.tpu_address\n",
    "dtype = cfg.trainer.dtype\n",
    "epochs = cfg.trainer.epochs\n",
    "strategy = cfg.trainer.strategy\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = cfg.optimizer.learning_rate\n",
    "loass_type = cfg.optimizer.loss_type\n",
    "\n",
    "# Data name\n",
    "data_name = cfg.glue.data.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3728a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c6f35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/jovyan/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "INFO:absl:Total individual observations/examples written is 500 in 0.36572909355163574 seconds\n",
      "INFO:absl:All writer objects closed\n",
      "INFO:absl:Total individual observations/examples written is 500 in 0.3345170021057129 seconds\n",
      "INFO:absl:All writer objects closed\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# Load data\n",
    "data = datasets.load_dataset(\"glue\", data_name)\n",
    "tfrecord_dir = tempfile.mkdtemp()\n",
    "\n",
    "train_dataset, total_train_examples = get_dataset(data, train_batch_size,tokenizer, max_seq_length, \"train\", tfrecord_dir, take_sample)\n",
    "eval_dataset, total_eval_examples  = get_dataset(data, eval_batch_size,tokenizer, max_seq_len, \"eval\", tfrecord_dir, take_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "791c58d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "# Load optimizer\n",
    "optimizer_fn = get_optimizer(learning_rate, total_train_examples, train_batch_size, epochs)\n",
    "\n",
    "# Load trainer\n",
    "trainer = get_trainer(device, dtype, strategy, num_gpus, tpu_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe5a1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2020d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f6ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type albert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "INFO:absl:Successful: Model checkpoints matched and loaded from /tmp/tf_transformers_cache/albert-base-v2/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc01a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 93) (32, 1)\n"
     ]
    }
   ],
   "source": [
    "for (batch_inputs, batch_labels) in train_dataset.take(1):\n",
    "    print(batch_inputs['input_ids'].shape, batch_labels['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d81dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a585e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_output': <tf.Tensor: shape=(32, 768), dtype=float32, numpy=\n",
       " array([[ 0.7143398 , -0.65813   , -0.9785618 , ...,  0.99996495,\n",
       "          0.99999976,  0.5848551 ],\n",
       "        [ 0.0306453 ,  0.00973307, -0.99677414, ...,  0.9994981 ,\n",
       "         -0.38448253, -0.11974888],\n",
       "        [-0.40589306,  0.49201494, -0.99863875, ...,  0.99995124,\n",
       "          0.41152513, -0.48804575],\n",
       "        ...,\n",
       "        [-0.45018688,  0.6705278 , -0.98600817, ...,  0.9998185 ,\n",
       "         -0.31839788, -0.6285347 ],\n",
       "        [-0.42206424,  0.6171094 , -0.992722  , ...,  0.9996224 ,\n",
       "          0.9642419 , -0.5217529 ],\n",
       "        [ 0.2351484 , -0.28753084, -0.99572015, ...,  0.99625677,\n",
       "         -0.9023692 ,  0.3213496 ]], dtype=float32)>,\n",
       " 'token_embeddings': <tf.Tensor: shape=(32, 93, 768), dtype=float32, numpy=\n",
       " array([[[ 1.5806692 , -1.2263874 ,  1.4549923 , ..., -1.0687431 ,\n",
       "          -0.5606896 ,  1.2192034 ],\n",
       "         [-0.7002921 , -0.40231714, -1.216911  , ..., -0.23197146,\n",
       "           0.25958478, -0.28148273],\n",
       "         [ 0.8397726 , -0.48121792,  0.5739545 , ...,  0.56749153,\n",
       "           1.8509921 , -0.06178978],\n",
       "         ...,\n",
       "         [ 0.82412016, -0.13620687, -0.42126253, ..., -0.29098707,\n",
       "           0.93279016, -1.4328613 ],\n",
       "         [-0.2509746 ,  0.26516762, -1.3836079 , ...,  0.21514063,\n",
       "           1.5946751 , -0.91573334],\n",
       "         [-0.42780086,  0.34500384, -1.4503222 , ...,  0.2933994 ,\n",
       "           1.5504308 , -0.7868708 ]],\n",
       " \n",
       "        [[ 0.79124475, -1.7979804 , -0.686834  , ...,  0.04932649,\n",
       "          -1.5137371 , -1.0421407 ],\n",
       "         [-0.21840534,  0.16629632,  0.5516379 , ..., -0.27723894,\n",
       "           1.7146116 , -2.1172142 ],\n",
       "         [-1.0070903 , -0.8299017 , -0.48397192, ..., -0.34594247,\n",
       "           1.2774717 ,  0.5387172 ],\n",
       "         ...,\n",
       "         [-0.7658887 ,  0.21276633,  0.54996514, ...,  0.5775138 ,\n",
       "           1.8007342 , -1.0153756 ],\n",
       "         [-1.0800966 ,  0.19040081,  0.64112675, ...,  0.42849708,\n",
       "           1.9172391 , -0.577436  ],\n",
       "         [-1.321645  ,  0.30731216,  0.6235294 , ...,  0.2573653 ,\n",
       "           2.0448875 , -0.5357454 ]],\n",
       " \n",
       "        [[ 0.8721585 , -1.2163043 , -0.00830233, ..., -1.1549219 ,\n",
       "          -1.4870597 , -0.49675333],\n",
       "         [-1.2872686 , -1.035641  , -0.4881184 , ...,  0.46511713,\n",
       "           0.64145106, -1.1383793 ],\n",
       "         [-0.59370387, -0.61665493,  0.08431986, ...,  0.43351424,\n",
       "           0.58720595, -2.017444  ],\n",
       "         ...,\n",
       "         [-0.44840515,  0.16312562,  0.16211838, ...,  0.3984233 ,\n",
       "           1.2549626 , -1.5372018 ],\n",
       "         [-0.6841981 , -0.36858326,  0.18229698, ...,  0.98826516,\n",
       "           1.7002736 , -0.7758089 ],\n",
       "         [-0.7731273 , -0.3510955 ,  0.14425206, ...,  0.96971756,\n",
       "           1.6268066 , -0.8324186 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.39500943, -1.8259611 , -0.6093285 , ...,  0.08744097,\n",
       "           0.43954396, -0.6036301 ],\n",
       "         [-1.4441328 , -1.1078945 , -0.37635812, ..., -0.51063883,\n",
       "           1.269672  , -0.9414989 ],\n",
       "         [ 0.28652748, -0.20757222, -0.76342547, ...,  0.7482983 ,\n",
       "           1.9231279 , -0.04117981],\n",
       "         ...,\n",
       "         [-0.3640086 , -0.05051883,  0.14395344, ...,  0.46689838,\n",
       "           1.5296798 , -1.520113  ],\n",
       "         [-0.3112895 ,  0.04702865, -0.13416825, ...,  0.986943  ,\n",
       "           2.1939323 , -1.2456658 ],\n",
       "         [-0.5017321 , -0.278222  , -0.74209255, ...,  0.6526659 ,\n",
       "           2.3786488 , -0.7291422 ]],\n",
       " \n",
       "        [[ 1.1909521 , -1.2806278 ,  0.59224606, ..., -0.7791715 ,\n",
       "          -0.23242581, -0.7313581 ],\n",
       "         [-1.4035568 , -0.80476326, -0.10195312, ...,  0.16142866,\n",
       "           2.1956632 , -2.6504648 ],\n",
       "         [ 0.12043771, -1.5423832 , -0.3704103 , ...,  0.22421323,\n",
       "           1.8075258 , -0.66714954],\n",
       "         ...,\n",
       "         [-0.62345433, -0.0576689 , -0.8092814 , ...,  1.1182212 ,\n",
       "           1.8509526 , -1.296749  ],\n",
       "         [-0.75911015, -0.10615592, -0.90529686, ...,  1.0792769 ,\n",
       "           1.8588552 , -1.3175392 ],\n",
       "         [-0.96266437, -0.09060726, -0.89435214, ...,  1.122725  ,\n",
       "           1.8019885 , -1.4624659 ]],\n",
       " \n",
       "        [[ 2.4709902 , -1.7813382 ,  0.0276939 , ...,  0.79152083,\n",
       "          -0.77637076, -0.62895477],\n",
       "         [-0.677689  , -0.14461628, -0.8795342 , ...,  1.6647034 ,\n",
       "           0.5453655 ,  0.5177852 ],\n",
       "         [-0.14336306,  0.6709526 , -1.485711  , ...,  1.4275066 ,\n",
       "           0.36474365,  2.0678518 ],\n",
       "         ...,\n",
       "         [-0.24377878,  0.36252534,  0.3168906 , ...,  0.71869063,\n",
       "           1.834237  , -2.1841044 ],\n",
       "         [-0.1975201 ,  0.4208508 , -0.0183432 , ...,  1.0487965 ,\n",
       "           1.6964962 , -1.6087013 ],\n",
       "         [-0.19285609,  0.42739823, -0.01400598, ...,  1.063843  ,\n",
       "           1.7243905 , -1.6312115 ]]], dtype=float32)>,\n",
       " 'token_logits': <tf.Tensor: shape=(32, 93, 30000), dtype=float32, numpy=\n",
       " array([[[ 1.45370588e+01,  1.33652544e+00, -2.69446325e+00, ...,\n",
       "          -7.26782370e+00, -8.73985672e+00, -1.90456450e+00],\n",
       "         [-8.20691299e+00,  4.88972068e-01, -2.75055480e+00, ...,\n",
       "          -3.55520797e+00, -2.01796269e+00,  1.62070847e+00],\n",
       "         [ 2.57915998e+00,  2.74856901e+00,  2.01521850e+00, ...,\n",
       "          -2.37142658e+00, -4.62866306e+00, -4.42838907e+00],\n",
       "         ...,\n",
       "         [-3.32504964e+00,  4.22917366e+00,  2.84195662e+00, ...,\n",
       "          -4.45165014e+00, -5.97636700e-01,  1.76879609e+00],\n",
       "         [-5.25855541e+00,  2.39325166e+00, -1.44698036e+00, ...,\n",
       "          -4.49882412e+00, -2.22389603e+00,  2.80669212e+00],\n",
       "         [-6.07694674e+00,  1.85531139e+00, -2.16208291e+00, ...,\n",
       "          -4.46995401e+00, -2.28372407e+00,  2.67561054e+00]],\n",
       " \n",
       "        [[ 1.68777428e+01, -1.07543623e+00, -8.31943810e-01, ...,\n",
       "          -5.34945297e+00, -1.12744093e+01, -4.70650434e+00],\n",
       "         [-3.10086870e+00, -4.66560185e-01, -1.02268515e+01, ...,\n",
       "          -1.10764980e+01, -5.96018061e-02, -6.69992971e+00],\n",
       "         [-8.24827671e+00, -1.84893835e+00, -9.87593555e+00, ...,\n",
       "          -6.38076544e+00, -2.47010565e+00, -5.30991936e+00],\n",
       "         ...,\n",
       "         [-3.69353008e+00, -1.05407917e+00, -4.24130058e+00, ...,\n",
       "          -1.02409935e+01, -2.20410776e+00, -2.18136406e+00],\n",
       "         [-2.65844631e+00, -1.54021239e+00, -5.06329966e+00, ...,\n",
       "          -1.15727253e+01, -3.68532586e+00, -2.54731011e+00],\n",
       "         [-2.91984868e+00, -1.76312602e+00, -5.12193298e+00, ...,\n",
       "          -1.19062662e+01, -3.72451329e+00, -2.91125798e+00]],\n",
       " \n",
       "        [[ 1.37708035e+01, -3.55329603e-01, -2.22043467e+00, ...,\n",
       "          -5.61841726e+00, -1.40490513e+01, -1.55043632e-01],\n",
       "         [-5.82551384e+00, -6.22262001e+00, -8.11035347e+00, ...,\n",
       "          -5.35895634e+00, -4.41265297e+00, -3.83605456e+00],\n",
       "         [ 1.29331613e+00, -4.84978294e+00,  3.29414439e+00, ...,\n",
       "          -1.96764338e+00, -8.17026019e-01, -2.76349616e+00],\n",
       "         ...,\n",
       "         [-5.96102190e+00,  1.84650958e+00,  1.35243928e+00, ...,\n",
       "          -3.39508820e+00, -9.44912076e-01, -1.46254241e+00],\n",
       "         [-6.47096348e+00, -5.49024761e-01, -1.47461653e+00, ...,\n",
       "          -4.71687412e+00, -2.09273076e+00, -7.86095917e-01],\n",
       "         [-6.78323603e+00, -4.83009160e-01, -1.41386914e+00, ...,\n",
       "          -4.82146215e+00, -1.93586743e+00, -8.30301046e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 8.73548126e+00, -1.96759236e+00, -2.21959472e+00, ...,\n",
       "          -1.01738091e+01, -8.93768024e+00, -1.64952588e+00],\n",
       "         [-1.59623957e+00, -1.30015677e-02, -6.08361816e+00, ...,\n",
       "          -8.42134190e+00, -4.12884623e-01, -6.75818062e+00],\n",
       "         [-3.35559082e+00, -1.47318923e+00, -4.32660246e+00, ...,\n",
       "          -9.56294060e+00, -3.70082855e+00, -1.75626719e+00],\n",
       "         ...,\n",
       "         [-5.59148121e+00,  5.70296288e+00,  1.69313467e+00, ...,\n",
       "          -4.23692799e+00,  1.09163141e+00, -2.16389132e+00],\n",
       "         [-9.21477604e+00,  4.54815865e+00, -8.18393528e-01, ...,\n",
       "          -6.52254963e+00,  2.92464828e+00, -9.27702785e-02],\n",
       "         [-9.11099148e+00,  6.37376368e-01, -3.95208812e+00, ...,\n",
       "          -9.27629662e+00,  3.93615842e+00,  7.87215233e-02]],\n",
       " \n",
       "        [[ 8.69815922e+00, -1.99582964e-01, -5.23775578e+00, ...,\n",
       "          -1.06042757e+01, -1.35658607e+01, -3.80460215e+00],\n",
       "         [-8.89109039e+00, -1.04425204e+00, -7.75910425e+00, ...,\n",
       "          -1.74002476e+01, -1.05751431e+00, -8.13134193e+00],\n",
       "         [ 4.12308121e+00,  3.04611921e+00,  5.56320763e+00, ...,\n",
       "          -4.63544703e+00,  1.50355950e-01, -1.81638730e+00],\n",
       "         ...,\n",
       "         [-8.37460804e+00,  2.88243580e+00, -1.23546422e+00, ...,\n",
       "          -8.87753487e+00,  2.72870868e-01, -2.24156022e+00],\n",
       "         [-8.40979576e+00,  2.38033748e+00, -1.55215645e+00, ...,\n",
       "          -9.27668762e+00, -3.43672745e-03, -2.09199595e+00],\n",
       "         [-7.76686144e+00,  2.58303475e+00, -1.35963929e+00, ...,\n",
       "          -9.29356384e+00, -6.39970927e-03, -2.15251255e+00]],\n",
       " \n",
       "        [[ 1.18180981e+01, -4.68298674e+00, -5.12902451e+00, ...,\n",
       "          -1.10370216e+01, -9.44629860e+00, -6.54583275e-01],\n",
       "         [-6.48599482e+00, -7.16861916e+00, -1.09772122e+00, ...,\n",
       "          -1.07201614e+01, -5.96873617e+00, -2.70716691e+00],\n",
       "         [-3.09987998e+00,  1.40433991e+00, -2.37841654e+00, ...,\n",
       "          -1.17111683e+01, -9.99406052e+00, -3.40400934e+00],\n",
       "         ...,\n",
       "         [-1.01346245e+01,  3.09782958e+00, -1.44612992e+00, ...,\n",
       "          -5.69375992e+00,  2.91711473e+00,  1.09128284e+00],\n",
       "         [-1.09801617e+01,  2.30011964e+00, -4.00605726e+00, ...,\n",
       "          -7.70848894e+00,  2.67705584e+00,  2.93272853e+00],\n",
       "         [-1.08637199e+01,  2.19770098e+00, -3.96547318e+00, ...,\n",
       "          -7.56749058e+00,  2.50121093e+00,  3.06721187e+00]]],\n",
       "       dtype=float32)>,\n",
       " 'last_token_logits': <tf.Tensor: shape=(32, 30000), dtype=float32, numpy=\n",
       " array([[-6.0769467e+00,  1.8553114e+00, -2.1620829e+00, ...,\n",
       "         -4.4699540e+00, -2.2837241e+00,  2.6756105e+00],\n",
       "        [-2.9198487e+00, -1.7631260e+00, -5.1219330e+00, ...,\n",
       "         -1.1906266e+01, -3.7245133e+00, -2.9112580e+00],\n",
       "        [-6.7832360e+00, -4.8300916e-01, -1.4138691e+00, ...,\n",
       "         -4.8214622e+00, -1.9358674e+00, -8.3030105e-01],\n",
       "        ...,\n",
       "        [-9.1109915e+00,  6.3737637e-01, -3.9520881e+00, ...,\n",
       "         -9.2762966e+00,  3.9361584e+00,  7.8721523e-02],\n",
       "        [-7.7668614e+00,  2.5830348e+00, -1.3596393e+00, ...,\n",
       "         -9.2935638e+00, -6.3997093e-03, -2.1525126e+00],\n",
       "        [-1.0863720e+01,  2.1977010e+00, -3.9654732e+00, ...,\n",
       "         -7.5674906e+00,  2.5012109e+00,  3.0672119e+00]], dtype=float32)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10851126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7711b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def call(trainer_kwargs):\n",
    "        \n",
    "        for k, v in trainer_kwargs.items():\n",
    "            print(k, '-->', v)\n",
    "callback = Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b492593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.run(\n",
    "    model_fn = get_model,\n",
    "    optimizer_fn = optimizer_fn,\n",
    "    train_dataset = train_dataset,\n",
    "    train_loss_fn,\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    model_checkpoint_dir,\n",
    "    batch_size,\n",
    "    training_loss_names=None,\n",
    "    validation_loss_names=None,\n",
    "    validation_dataset=None,\n",
    "    validation_loss_fn=None,\n",
    "    validation_interval_steps=None,\n",
    "    steps_per_call=100,\n",
    "    enable_xla=True,\n",
    "    callbacks=None,\n",
    "    callbacks_interval_steps=None,\n",
    "    overwrite_checkpoint_dir=False,\n",
    "    max_number_of_models=10,\n",
    "    model_save_interval_steps=None,\n",
    "    repeat_dataset=True,\n",
    "    latest_checkpoint=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
